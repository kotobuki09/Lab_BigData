{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Event Time\n",
    "Event time is an important topic to cover discretely because Spark’s DStream API does not\n",
    "support processing information with respect to event-time. At a higher level, in streamprocessing\n",
    "systems there are effectively two relevant times for each event: the time at which it\n",
    "actually occurred (event time), and the time that it was processed or reached the streamprocessing\n",
    "system (processing time).\n",
    "## Event time\n",
    "Event time is the time that is embedded in the data itself. It is most often, though not required\n",
    "to be, the time that an event actually occurs. This is important to use because it provides a\n",
    "more robust way of comparing events against one another. The challenge here is that event\n",
    "data can be late or out of order. This means that the stream processing system must be able to\n",
    "handle out-of-order or late data.\n",
    "## Processing time\n",
    "Processing time is the time at which the stream-processing system actually receives data.\n",
    "This is usually less important than event time because when it’s processed is largely an\n",
    "implementation detail. This can’t ever be out of order because it’s a property of the streaming\n",
    "system at a certain time (not an external system like event time).\n",
    "\n",
    "# Stateful Processing\n",
    "The other topic we need to cover in this chapter is stateful processing. Actually, we already\n",
    "demonstrated this many times in Chapter 21. Stateful processing is only necessary when you\n",
    "need to use or update intermediate information (state) over longer periods of time (in either a\n",
    "microbatch or a record-at-a-time approach). This can happen when you are using event time or\n",
    "when you are performing an aggregation on a key, whether that involves event time or not.\n",
    "\n",
    "For the most part, when you’re performing stateful operations. Spark handles all of this\n",
    "complexity for you. For example, when you specify a grouping, Structured Streaming maintains\n",
    "and updates the information for you. You simply specify the logic. When performing a stateful\n",
    "operation, Spark stores the intermediate information in a state store. Spark’s current state store\n",
    "implementation is an in-memory state store that is made fault tolerant by storing intermediate\n",
    "state to the checkpoint directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
